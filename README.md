# ViT Fine-Tuning on CIFAR-10

This project demonstrates **fine-tuning the Vision Transformer (ViT)** model for **image classification** using the **CIFAR-10 dataset**.  
It leverages the **Hugging Face Transformers** and **Datasets** libraries to perform model training, validation, and evaluation.

---

## Project Overview
- Loads and preprocesses the CIFAR-10 dataset.  
- Applies data augmentation and normalization using **torchvision transforms**.  
- Fine-tunes the **`google/vit-base-patch16-224-in21k`** model on CIFAR-10.  
- Evaluates model performance using **accuracy** and **confusion matrix**.  
- Compares inference between:
  - Pretrained ViT model
  - Fine-tuned ViT model
  - BEiT model for reference

---

## Technologies Used
- **Python**
- **Hugging Face Transformers**
- **Torch / Torchvision**
- **Datasets (Hugging Face)**
- **scikit-learn**
- **PIL (Pillow)**

---

## Hello and Welcome

Thank you for visiting my GitHub page!  
I’m currently in the process of uploading my previous projects and doing my best to make them publicly available in an organized and clear manner.  

At the moment, I’m adding each project with some **light updates and clarifying adjustments**, and I plan to include more **comprehensive notes, explanations, and detailed READMEs** very soon — to help others better understand each project’s idea and usage.  

If you have any questions, suggestions, or would simply like to connect, I’d be delighted to hear from you:  
- [LinkedIn](https://www.linkedin.com/in/wajdalrabiah)  
- [X (Twitter)](https://x.com/wajdalrabiah)  

Thank you again for your time and interest.  
Your feedback and interaction are always appreciated

> _More updates coming soon — stay tuned!_  
